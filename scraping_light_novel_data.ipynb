{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LN_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ZVS7XVsEvDPHM7_NqOvLPbxO06kk_8K3",
      "authorship_tag": "ABX9TyOQjZucTHIexZ7cE0G6Su/F"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXp463PwwWZt",
        "outputId": "9b75730a-c998-41f8-8f10-ebbff4ed21cc"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from string import ascii_uppercase #alphabet\n",
        "from  nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "import time \n",
        "import concurrent.futures as cp"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaZitqRvYc1x"
      },
      "source": [
        "# Scraping readlighnovel.me to create a light novel dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovoYfOlMYkXY"
      },
      "source": [
        "## Scraping novel list page to get links to all available novels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGXtPYaMwegn"
      },
      "source": [
        "START_URL = 'https://www.readlightnovel.me/novel-list'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BI5Z1xOwvxs"
      },
      "source": [
        "# get a list of urls to different light novels\n",
        "novel_links = []\n",
        "for letter in ascii_uppercase:\n",
        "  # Handle all of the letter names\n",
        "  r = requests.get(START_URL+'/'+letter, stream=True)\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  li_s = [a.find('a') for a in soup.find_all('li')]\n",
        "  for li in li_s:\n",
        "    if li.has_attr('data-wrapper'):\n",
        "      novel_links.append(li.get('href'))\n",
        "\n",
        "# For non-letter first character the website simply uses the / so we get those too\n",
        "r = requests.get(START_URL+'/', stream=True)\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "li_s = [a.find('a') for a in soup.find_all('li')]\n",
        "for li in li_s:\n",
        "  if li.has_attr('data-wrapper'):\n",
        "    novel_links.append(li.get('href'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4L8gVfPyKV_",
        "outputId": "4dcd86ec-be6d-43bc-faa9-87c3d3ce1243"
      },
      "source": [
        "# Number of links/ novels we got\n",
        "len(novel_links)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5681"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8cmscvfYqk-"
      },
      "source": [
        "## For each novel we plan to extract:\n",
        "* Name\n",
        "* Description\n",
        "* Number of chapters\n",
        "* Rating\n",
        "* Genre\n",
        "* Views\n",
        "* Random Chapter?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxUP623dZip3"
      },
      "source": [
        "### Trying for one novel first"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFbUGVsdYL0e",
        "outputId": "3e6f0db5-11b4-4c1b-e47c-03e6f5b35b83"
      },
      "source": [
        "# Which novel are we getting:\n",
        "link = novel_links[0]\n",
        "print(link)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.readlightnovel.me/a-barbaric-proposal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7kk-wTMX7ls"
      },
      "source": [
        "r = requests.get(link, stream=True)\n",
        "soup = BeautifulSoup(r.text, 'html.parser')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5-fbLMbdvyA"
      },
      "source": [
        "#### Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyi_Q2UlaQY_",
        "outputId": "5b1ef334-e654-4e7d-dc39-93e51027559a"
      },
      "source": [
        "# title\n",
        "print(soup.find('div', {'class':'block-title'}).text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A Barbaric Proposal\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qua2_ZjmdyDC"
      },
      "source": [
        "#### Detail\n",
        "I was going for just genre, but the website made it super convenient to get a bunch of metadata, so I just grab it all"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mE1St4mbQo-"
      },
      "source": [
        "# Getting all of the details\n",
        "details = soup.findAll('div', {'class':'novel-detail-item'})\n",
        "detail_content = {}\n",
        "for detail in details:\n",
        "  try:\n",
        "    # Match header and content into a dict\n",
        "    header = detail.find('div',{'class': 'novel-detail-header'}).text.strip()\n",
        "    detail_content[header] = detail.find('div',{'class': 'novel-detail-body'}).text.strip().split('\\n')\n",
        "    \n",
        "    # breaks if we go after rating so we break for loop\n",
        "  except:\n",
        "    #print(detail.findAll('a'))\n",
        "    None"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGmTqafrcyos",
        "outputId": "9888a18b-8e53-478d-94b4-a403706a0f78"
      },
      "source": [
        "detail_content"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Alternative Names': ['ABP 야만의 청혼'],\n",
              " 'Artist(s)': ['N/A'],\n",
              " 'Author(s)': ['齐成琨'],\n",
              " 'Description': ['“I already have a child with another man.”',\n",
              "  'It was a lie made in order to refuse the proposal of the leader of the most feared mercenary company in the entire country. But his response was unexpected.',\n",
              "  '“It doesn’t matter who the child is. Just birth it.”',\n",
              "  'She couldn’t understand.',\n",
              "  'What could this man possibly want with the princess of a failing nation?'],\n",
              " 'Genre': ['Drama', 'Fantasy', 'Josei', 'Romance'],\n",
              " 'Language': ['Korean'],\n",
              " 'Latest Chapters': ['Chapter 52',\n",
              "  ' Chapter 51',\n",
              "  ' Chapter 50',\n",
              "  ' Chapter 49',\n",
              "  ' Chapter 48'],\n",
              " 'Rating': ['7.5'],\n",
              " 'Status': ['Ongoing'],\n",
              " 'Tags': ['N/A'],\n",
              " 'Total Views': ['24791'],\n",
              " 'Type': ['Web Novel'],\n",
              " 'Year': ['N/A'],\n",
              " 'You May Also Like': ['Totem(Ongoing)',\n",
              "  'The Eldest Daughter is Beautiful and Saucy(Ongoing)',\n",
              "  'Quick Transmigration: Male Lead, You’re Overpowered?(Ongoing)',\n",
              "  'I’m Only a Stepmother, but My Daughter is Just so Cute!(Ongoing)',\n",
              "  'Reincarnated Maid is About To Be Captured by All Players(Ongoing)']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vekyJsEBd7d8"
      },
      "source": [
        "#### Chapter count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIYHBOtddgr5",
        "outputId": "c0039bf1-2b1d-4762-d74b-4b1e21fae103"
      },
      "source": [
        "# Getting the latest chapter number \n",
        "detail_top = soup.findAll('div', {'class':'novel-detail-body'})\n",
        "chap_count = int(re.findall(r'([0-9]+)', detail_top[-1].find('a').get('href'))[-1])\n",
        "print(chap_count)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTTpBsH5d9gQ"
      },
      "source": [
        "#### Content from a random chapter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWaIieJTxKuJ",
        "outputId": "7137ffb1-dd9c-4246-e3de-3853b47c4c52"
      },
      "source": [
        "# Generate a number from 1 to chapter count and get the content of that chapter\n",
        "rand_chapter = random.randint(1, chap_count)\n",
        "print(rand_chapter)\n",
        "rand_chapter = 51\n",
        "r = requests.get(link+'/chapter-'+str(rand_chapter), stream=True)\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "\n",
        "# since content is copyrighted we extract only word counts\n",
        "content = [par.text for par in soup.find('div', {'class':'desc'}).findAll('p')]\n",
        "# Join to string, extract all of the unicode characters, and remove stopwords\n",
        "content = [word for word in re.findall(r'\\w+', ' '.join(content)) if word not in stopwords.words('english')]\n",
        "# get counts of the output\n",
        "content = Counter(content).most_common(100)\n",
        "content"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Rienne', 273),\n",
              " ('Black', 225),\n",
              " ('I', 207),\n",
              " ('like', 66),\n",
              " ('face', 45),\n",
              " ('What', 42),\n",
              " ('would', 39),\n",
              " ('She', 36),\n",
              " ('hand', 36),\n",
              " ('eyes', 33),\n",
              " ('It', 33),\n",
              " ('know', 33),\n",
              " ('felt', 33),\n",
              " ('But', 33),\n",
              " ('Mrs', 30),\n",
              " ('Flambard', 30),\n",
              " ('And', 30),\n",
              " ('lips', 30),\n",
              " ('one', 30),\n",
              " ('He', 30),\n",
              " ('Princess', 27),\n",
              " ('sleep', 27),\n",
              " ('close', 27),\n",
              " ('The', 27),\n",
              " ('right', 24),\n",
              " ('feeling', 24),\n",
              " ('words', 24),\n",
              " ('think', 24),\n",
              " ('back', 24),\n",
              " ('You', 24),\n",
              " ('That', 21),\n",
              " ('bed', 21),\n",
              " ('could', 21),\n",
              " ('saying', 21),\n",
              " ('said', 21),\n",
              " ('talking', 21),\n",
              " ('things', 21),\n",
              " ('away', 21),\n",
              " ('blanket', 21),\n",
              " ('time', 18),\n",
              " ('head', 18),\n",
              " ('something', 18),\n",
              " ('If', 18),\n",
              " ('still', 18),\n",
              " ('pulled', 18),\n",
              " ('wanted', 18),\n",
              " ('found', 18),\n",
              " ('kiss', 18),\n",
              " ('Then', 15),\n",
              " ('need', 15),\n",
              " ('So', 15),\n",
              " ('really', 15),\n",
              " ('Well', 15),\n",
              " ('much', 15),\n",
              " ('coming', 15),\n",
              " ('turned', 15),\n",
              " ('took', 15),\n",
              " ('anything', 15),\n",
              " ('heart', 15),\n",
              " ('already', 15),\n",
              " ('going', 15),\n",
              " ('say', 15),\n",
              " ('worried', 15),\n",
              " ('together', 15),\n",
              " ('body', 15),\n",
              " ('scar', 15),\n",
              " ('voice', 12),\n",
              " ('tell', 12),\n",
              " ('good', 12),\n",
              " ('far', 12),\n",
              " ('tonight', 12),\n",
              " ('There', 12),\n",
              " ('side', 12),\n",
              " ('left', 12),\n",
              " ('mouth', 12),\n",
              " ('pillows', 12),\n",
              " ('sound', 12),\n",
              " ('gently', 12),\n",
              " ('stopped', 12),\n",
              " ('came', 12),\n",
              " ('thinking', 12),\n",
              " ('As', 12),\n",
              " ('ask', 12),\n",
              " ('way', 12),\n",
              " ('even', 12),\n",
              " ('cold', 12),\n",
              " ('next', 12),\n",
              " ('moved', 12),\n",
              " ('fingers', 12),\n",
              " ('chest', 12),\n",
              " ('No', 9),\n",
              " ('matter', 9),\n",
              " ('may', 9),\n",
              " ('though', 9),\n",
              " ('looked', 9),\n",
              " ('around', 9),\n",
              " ('strange', 9),\n",
              " ('Yes', 9),\n",
              " ('woman', 9),\n",
              " ('mean', 9)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zA0PreGaTh4"
      },
      "source": [
        "### Repeat for all of the novels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm6J8YmGAU8b"
      },
      "source": [
        "def get_link(link, N_common=100):\n",
        "  r = requests.get(link, stream=True)\n",
        "  soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  novel_data = {}\n",
        "\n",
        "  # name\n",
        "  novel_data['title'] = soup.find('div', {'class':'block-title'}).text.strip()\n",
        "\n",
        "  # details\n",
        "  details = soup.findAll('div', {'class':'novel-detail-item'})\n",
        "  for detail in details:\n",
        "    try:\n",
        "      # Match header and content into a dict\n",
        "      header = detail.find('div',{'class': 'novel-detail-header'}).text.strip()\n",
        "      novel_data[header] = detail.find('div',{'class': 'novel-detail-body'}).text.strip().split('\\n')\n",
        "      \n",
        "      # breaks if we go after rating so we break for loop\n",
        "    except:\n",
        "      # printing to keep track of what we missed\n",
        "      #print(detail.findAll('a'))\n",
        "      None\n",
        "\n",
        "  # Chapter Count\n",
        "  try:\n",
        "    detail_top = soup.findAll('div', {'class':'novel-detail-body'})\n",
        "    # We added a small hack here for novels that end in non-numbered chapters\n",
        "    # Drawback being that if we try to get the content of these chapters we will get errors\n",
        "    novel_data['chap_count'] = int(re.findall(r'([0-9]+)', detail_top[-1].findAll('a')[-3].get('href'))[-1])+2\n",
        "\n",
        "    # Random chapter counter\n",
        "    novel_data['rand_chapter'] = random.randint(1, chap_count) #inclusive so we are good :)\n",
        "\n",
        "    r = requests.get(link+'/chapter-'+str(novel_data[rand_chapter]), stream=True)\n",
        "    soup = BeautifulSoup(r.text, 'html.parser')\n",
        "  except:\n",
        "    None\n",
        "      \n",
        "\n",
        "  try:\n",
        "    # since content is copyrighted we extract only word counts\n",
        "     content = [par.text for par in soup.find('div', {'class':'desc'}).findAll('p')]\n",
        "    # Join to string & extract all of the unicode characters\n",
        "     content = [word for word in re.findall(r'\\w+', ' '.join(content)) if word not in stopwords.words('english')]\n",
        "    # get counts of the output\n",
        "     novel_data['content_counts'] = Counter(content).most_common(N_common)\n",
        "  except:\n",
        "     None\n",
        "  time.sleep(30)\n",
        "  return novel_data"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5nZNPMBxGPQ"
      },
      "source": [
        "novels = []\n",
        "\n",
        "# Thread the grabbing of data\n",
        "with cp.ThreadPoolExecutor() as ex:\n",
        "  # We iterate over links instead of using map to avoid data loss if connection fails\n",
        "  futures = []\n",
        "  for link in novel_links:\n",
        "    futures.append(ex.submit(get_link, link))\n",
        "\n",
        "  for future in cp.as_completed(futures):\n",
        "    novels.append(future.result())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crbk8htN1QIn"
      },
      "source": [
        "df = pd.DataFrame(novels)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcuFZSiq1YjP"
      },
      "source": [
        "df.to_csv('/content/drive/MyDrive/light_novel_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}